# Vision encoder: vit | clip
VISION_ENCODER=clip
# Top-K Qwen blocks to unfreeze (0 = fully frozen)
TOP_K=3

# Vision encoder model name: flickr30k, flation, fashion_mnist
TRAINING_DATASET=flickr30k

BRIDGE_CROSS_ENTROPY=True
BATCH_SAMPLING=200


# Core hyper-parameters (tweak as needed)
BATCH_SIZE=32
EPOCHS=3
LR_ADAPTER=1e-4
LR_QWEN=2e-5
SEED=42

# Logging / storage
OUTPUT_DIR_MODELS=../.data/models
OUTPUT_DIR_DATASETS=../.data/datasets
OUTPUT_DIR_CACHE=../.data/cache

WANDB_API_KEY=....
WANDB_ENTITY=charles-cai
WANDB_PROJECT=mlx8-w4-multimodal-transferlearning

# HF private token (optional)
HF_TOKEN=....

# Inference settings
INFERENCE_PROMPT=Examine the image carefully and provide a detailed description covering objects, people, actions, background, and any notable visual elements
# training settings
LIMITING_FACTOR=0.1