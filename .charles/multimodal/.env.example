# Vision encoder: vit | clip
VISION_ENCODER=clip
# Top-K Qwen blocks to unfreeze (0 = fully frozen)
TOP_K=3

# Vision encoder model name: flickr30k, flation, fashion_mnist
TRAINING_DATASET=flickr30k

# Core hyper-parameters (tweak as needed)
BATCH_SIZE=2
EPOCHS=3
LR_ADAPTER=1e-4
LR_QWEN=2e-5
SEED=42

# Logging / storage
OUTPUT_DIR_MODELS=../.data/models

WANDB_API_KEY=......
WANDB_ENTITY=charles-cai
WANDB_PROJECT=mlx8-w4-multimodal-transfer-learning

# HF private token (optional)
HF_TOKEN=...



uv run multimodal_transfer_learing.py --train
INFO     | üîÑ Mode: Training (with final test)
INFO     | üîí Set random seed to 42 for reproducibility.
INFO     | üîÑ Train mode: Initializing Qwen + bridge...
wandb: Currently logged in as: charles-cai to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/wandb/run-20250703_115057-vinemkcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flickr30k-clip-top0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/charles-cai/mlx8-w4-multimodal-transferlearning
wandb: üöÄ View run at https://wandb.ai/charles-cai/mlx8-w4-multimodal-transferlearning/runs/vinemkcf
INFO     | üé® W&B initialised ‚Üí mlx8-w4-multimodal-transferlearning/flickr30k-clip-top0
INFO     | üßä Keeping Qwen fully frozen.
INFO     | üîß Creating ImageAdapter: in_dim=512, vision_encoder=clip
INFO     | üìÅ Loading cached complete dataset from ../.data/cache/clip_flickr30k_complete.pt
WARNING  | ‚ö†Ô∏è Safe loading failed: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint. 
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL datasets.info.DatasetInfo was not an allowed global by default. Please use `torch.serialization.add_safe_globals([datasets.info.DatasetInfo])` or the `torch.serialization.safe_globals([datasets.info.DatasetInfo])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
WARNING  | üîÑ Falling back to weights_only=False (trusted source)
INFO     | ‚úÖ Loaded complete dataset with 158915 examples
INFO     | üìä Cache metadata: clip, 31783 images, 512D
INFO     | ‚è≥ Setting up data loaders...
INFO     | Tokenizing captions...
Processing train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127132/127132 [00:26<00:00, 4787.15 examples/s]
Processing eval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15891/15891 [00:03<00:00, 4901.01 examples/s]
Processing test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15892/15892 [00:03<00:00, 4926.98 examples/s]
INFO     | ‚úÖ Data loaders ready!
INFO     | üõ†Ô∏è  Optimiser ready (AdamW). Bridge params: 4, Qwen params: 0
INFO     | üöÄ Training setup complete!
INFO     | üèÉ Starting training for 3 epochs...
Epoch 1/3:   0%|                                         | 0/7946 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 665, in <module>
    main()
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 655, in main
    engine.train()
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 565, in train
    loss = self._forward_step(batch)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 508, in _forward_step
    vis_tokens = self.bridge(img_emb)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 119, in forward
    mapped = self.mapper(x).view(x.size(0), self.n_tokens, self.out_dim)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (16x768 and 512x1024)
Traceback (most recent call last):
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 665, in <module>
    main()
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 655, in main
    engine.train()
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 565, in train
    loss = self._forward_step(batch)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 508, in _forward_step
    vis_tokens = self.bridge(img_emb)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.charles/multimodal/multimodal_transfer_learing.py", line 119, in forward
    mapped = self.mapper(x).view(x.size(0), self.n_tokens, self.out_dim)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/_github/charles-cai/MLX8-W4-Multimodal-TransferLearning/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (16x768 and 512x1024)
wandb: 
wandb: üöÄ View run flickr30k-clip-top0 at: https://wandb.ai/charles-cai/mlx8-w4-multimodal-transferlearning/runs/vinemkcf
wandb: Find logs at: wandb/run-20250703_115057-vinemkcf/logs

root in üåê bbe0d4c6f2be in MLX8-W4-Multimodal-TransferLearning/.charles/multimodal on ÓÇ† main [!] via üêç v3.10.18 (mlx8-w4-multimodal-transferlearning) took 1m13s 
‚¨¢ [Docker] ‚ùØ 