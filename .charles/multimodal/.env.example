# Vision encoder: vit | clip
VISION_ENCODER=clip
# Top-K Qwen blocks to unfreeze (0 = fully frozen)
TOP_K=3

# Vision encoder model name: flickr30k, flation, fashion_mnist
TRAINING_DATASET=flickr30k

# Core hyper-parameters (tweak as needed)
BATCH_SIZE=2
EPOCHS=3
LR_ADAPTER=1e-4
LR_QWEN=2e-5
SEED=42

# Logging / storage
OUTPUT_DIR_MODELS=../.data/models

WANDB_API_KEY=......
WANDB_ENTITY=charles-cai
WANDB_PROJECT=mlx8-w4-multimodal-transfer-learning

# HF private token (optional)
HF_TOKEN=...